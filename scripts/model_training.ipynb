{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리들을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 제공 라이브러리\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 모델링에 사용되는 tensorflow 라이브러리\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자체적으로 제작된 모듈\n",
    "from datagenerator import TightFaceProvider\n",
    "from helper import glob_all_files, paths2numpy, cropper, show_images, draw_rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이후 작업에 GPU 를 사용하도록 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 를 사용하도록 설정\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습용, 검증용 데이터를 불러온 후 인공지능 모델 학습에 알맞게 가공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최상위 데이터 폴더명을 저장\n",
    "data_root_folder = 'sample_data2'\n",
    "\n",
    "# 학습용 이미지들의 경로를 불러옵니다.\n",
    "fg_folder = f\"../data/{data_root_folder}/train/wally\"\n",
    "bg_folder = f\"../data/{data_root_folder}/train/backgrounds\"\n",
    "\n",
    "val_fg_folder = f\"../data/{data_root_folder}/val/wally\"\n",
    "val_bg_folder = f\"../data/{data_root_folder}/val/backgrounds\"\n",
    "\n",
    "tfp = TightFaceProvider(fg_folder, bg_folder, val_fg_folder, val_bg_folder,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(tfp[0][0], titles=list(tfp[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 모델을 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 딥러닝 모델 구조 설정\n",
    "\n",
    "# 입력층\n",
    "inputs = Input(shape=(tfp.max_length+1, tfp.max_length+1, 3), name='inputs')\n",
    "\n",
    "# 은닉층\n",
    "# Convolutional Layer 1\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "# Convolutional Layer 2\n",
    "conv = Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "# Convolutional Layer 3\n",
    "conv = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(pool)\n",
    "norm = BatchNormalization()(conv)\n",
    "relu = ReLU()(norm)\n",
    "pool = MaxPooling2D()(relu)\n",
    "\n",
    "flat = Flatten()(pool)\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "fcn1 = Dense(units=256, kernel_initializer='he_normal')(flat)\n",
    "norm = BatchNormalization()(fcn1)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "# Fully Connected Layer 2\n",
    "fcn2 = Dense(units=256, kernel_initializer='he_normal')(relu)\n",
    "norm = BatchNormalization()(fcn2)\n",
    "relu = ReLU()(norm)\n",
    "\n",
    "# 출력층\n",
    "pred = Dense(units=1, activation='sigmoid')(relu)\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model(inputs, pred)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성된 모델을 저장할 경로 지정\n",
    "model_name = \"ai-kit_model\"\n",
    "model_dir = f\"../models/{model_name}\"\n",
    "\n",
    "# 위의 경로가 존재하지 않을 시, 새로 생성\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "weight_path= f\"../models/{model_name}/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 도중 loss 가 가장 적게 나온 모델을 저장하기 위한 callback 설정\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=weight_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델을 학습시키고, 제일 loss 가 적게 나온 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(tfp, validation_data=(tfp.get_validation_set()), epochs=5, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "# 모델 학습에 사용한 이미지 길이, 스트라이드 설정을 저장\n",
    "f = open(f\"{weight_path}.txt\", 'w')\n",
    "f.write(f\"{tfp.max_length+1}\\n\")\n",
    "f.write(f\"{tfp.stride}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 학습 동안의 loss 변화를 시각화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 동안의 loss 변화 시각화\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 진행한 학습 중 제일 loss 가 적게 나온 모델을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss 가 가장 적게 나온 가중치 불러오기\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 loss 가 적게 나온 모델을 저장\n",
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델을 평가용 데이터로 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 데이터가 들어있는 폴더 경로 가져오기\n",
    "test_folder = f\"../data/{data_root_folder}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에서 사용한 이미지 길이 및 스트라이드 설정 가져오기\n",
    "f = open(f\"{weight_path}.txt\", 'r')\n",
    "length = int(f.readline())\n",
    "stride = int(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 1: 월리가 있을 확률이 제일 높은 곳에만 빨간 사각형을 그린다.\n",
    "images = sorted(glob_all_files(test_folder))\n",
    "images = paths2numpy(images)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "\n",
    "    cropped_imgs, cropped_crds = cropper(image, stride, stride, length, length)\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 가장 높은 예측 값이 나온 부분에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "    bool_mask = np.where(predicts[:, 0] == np.max(predicts[:, 0]))\n",
    "    \n",
    "\n",
    "#     show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[bool_mask]     # 월리의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "\n",
    "    predicts = predicts[bool_mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "    print(f\"예측값: {predicts[0]}\")\n",
    "    result_image = draw_rectangles(image, target_crds, (255, 0, 0), 3, predicts[:, 0])\n",
    "\n",
    "    plt.figure().set_size_inches(20,20)\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# case 2: 월리가 있을 확률이 0.5 이상인 곳들에 빨간 사각형을 그린다.\n",
    "images = sorted(glob_all_files(test_folder))\n",
    "images = paths2numpy(images)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "\n",
    "    cropped_imgs, cropped_crds = cropper(image, stride, stride, length, length)\n",
    "\n",
    "    # 예측값을 저장한 후, 그 중 0.5가 넘는 값들에 대한 불리언 마스크를 만드는 부분입니다.\n",
    "    predicts = model.predict(cropped_imgs)\n",
    "    bool_mask = (predicts > 0.5)[:,0]\n",
    "    \n",
    "\n",
    "#     show_images(cropped_imgs[bool_mask])    # 불리언 마스크를 적용시킨 결과로 얻은 월리의 얼굴로 추정되는 이미지 조각들을 출력\n",
    "    target_crds = np.array(cropped_crds)[bool_mask]     # 월리의 얼굴이 있을 것으로 예상되는 좌표들을 저장\n",
    "\n",
    "    predicts = predicts[bool_mask]  # 불리언 마스크를 적용시켰을 때의 예측값을 저장\n",
    "    print(predicts)\n",
    "    result_image = draw_rectangles(image, target_crds, (255, 0, 0), 3, predicts[:, 0])\n",
    "\n",
    "    plt.figure().set_size_inches(20,20)\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_p36",
   "language": "python",
   "name": "tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
