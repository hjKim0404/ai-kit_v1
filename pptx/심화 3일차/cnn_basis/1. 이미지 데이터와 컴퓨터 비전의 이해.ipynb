{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_합성곱신경망(CNN) 기본기_**\n",
    "\n",
    "\n",
    "# 이미지 데이터와 컴퓨터 비전의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### _Objective_\n",
    "\n",
    "1. `이미지 데이터`를 넘파이 배열로 불러와 그 형태를 확인하고 특징과 구조를 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. `Dense` 층으로만 구성된 네트워크로`컴퓨터 비전`을 구현해보고 발생하는 어려움을 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. 동물의 시각이 사물을 인지하는 방법을 배우고 이를 컴퓨터 비전에 어떻게 이용할 수 있을지 생각해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 필요한 패키지 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [1. 이미지 데이터의 이해 ]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지 데이터의 표현\n",
    "\n",
    "---\n",
    "`PIL`또는 `Matplotlib` 를 통한 이미지데이터 불러오기.\n",
    "\n",
    "\n",
    "\n",
    "`PIL`(Python Imaging Library) : 다양한 이미지 파일 형식으로 이미지 처리와 그래픽 기능을 제공하는 라이브러리<br>\n",
    "`matplotlib` : 넘파이 배열을 기반으로 데이터의 다양한 시각화와 그래프 표현을 위한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install Pillow\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# matplotlib.pyplot은 주로 `plt` 별칭을 이용\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 웹의 이미지 불러오기\n",
    "\n",
    "`keras.utils`의 `get_file` : url 주소의 데이터가 캐시에 없을때만 불러와 캐시에 저장 <br>\n",
    "→ 현재 열려있는 파이썬에서 데이터를 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./img/1_1.png\" alt=\"1_1\" width=500px>\n",
    "\n",
    "(웹에서 원하는 이미지에 우클릭 후 이미지 주소 복사를 통해 위치를 가져올 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터 다운로드 받기\n",
    "fpath = get_file('lenna.jpg',' http://www.lenna.org/len_top.jpg')\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `PIL`로 이미지 파일 불러오기\n",
    "\n",
    "`PIL`의 `Image.open(fpath)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# PIL 로 불러오기\n",
    "image = Image.open(fpath)\n",
    "type(image) ## PIL의 객체로 저장\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터를 넘파이 배열로 변환해보기\n",
    "image_ary = np.array(image)\n",
    "image_ary ## 여러개의 숫자로 구성된 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `Matplotlib`로 이미지 확장자의 파일 불러오기\n",
    "\n",
    "`Matplotlib.pyplot(plt)`의 `.imread(fpath)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image = plt.imread(fpath)\n",
    "image ## plt를 사용하면 이미지 데이터가 바로 넘파이 배열로 불러와진다\n",
    "plt.imshow(image) ## plt를 사용하여 이미지 데이터를 저장한 배열을 그리는 방법\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 이미지 데이터 표현의 이해\n",
    "\n",
    "<img src=\"https://gscaltexmediahub.com/wp-content/uploads/2018/10/GSC_BS_MH_gs-calender-2019-04_20181026_01.jpg\" width=400px>\n",
    "\n",
    "+ 점묘법은 각 위치의 색상을 작은 점으로 찍어 그림을 그리는 미술 기법 중 하나이다.\n",
    "+ 위치와 색상값(세가지 색상)으로 그림 전체를 표현한다는 아이디어에서 디지털의 이미지 표현 방법을 도출했다.\n",
    "+ 이때, 각 점을 \"픽셀\" 이라고 한다.\n",
    "+ (빨강, 초록, 파랑)을 각각 그 세기에 따라 256가지로 나누고 조합하여 색상을 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![1_2](./img/1_2.png)\n",
    "\n",
    "이미지를 숫자로 표현하여 데이터를 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\" ⚠︎ plt를 활용하여 이미지 데이터를 읽을 경우 그 배열은 `read-only`이므로, 본 강의에서는 주로 PIL을 이용\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지 데이터의 구조\n",
    "\n",
    "---\n",
    "\n",
    "+ 넘파이 배열로 표현된 이미지 데이터의 구조\n",
    "+ 시각적으로 보이는 사진을 어떻게 데이터로 표현할 수 있을까\n",
    "\n",
    "(사진이나 동영상의 데이터를 다루는 분야를 \"영상처리(Image Processing)\"이라 한다.<br>\n",
    "이후, 본 강의에서 \"영상\" 이라 함은 흔히 아는 이미지 데이터를 의미한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# jpg 확장자인 이미지 데이터에서의 모양\n",
    "image = np.array(Image.open(fpath))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 첫번째 축의 의미 : 이미지의 세로 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째 축에서 일부만 가져온다면\n",
    "part = image[50:160] ## 값을 바꿔가며 이해하기\n",
    "plt.imshow(part)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 두번째 축의 의미 : 이미지의 가로 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 두번째 축에서 일부만 가져온다면\n",
    "part = image[:, 150:250] ## 값을 바꿔가며 이해하기\n",
    "plt.imshow(part)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 세번째 축의 의미 : 채널 RGB (빨간색, 초록색, 파란색)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 세 개의 채널 값\n",
    "image[0,1,:] ## 각각 RGB를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# R 위치의 값만 남긴다면\n",
    "one_channel = image.copy()\n",
    "one_channel[:,:,[1,2]] = 0\n",
    "plt.imshow(one_channel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# G 위치의 값만 남긴다면\n",
    "one_channel = image.copy()\n",
    "one_channel[:,:,[0,2]] = 0\n",
    "plt.imshow(one_channel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 이미지 데이터의 구성 요소 정리\n",
    "+ `jpg` 확장자의 이미지 : (세로 × 가로 × 채널(RGB)) 구성의 3차원 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### + `png` 확장자의 데이터 구조\n",
    "`png`확장자의 경우 투명도 A를 추가하여 (세로 × 가로 × 채널(RGBA))인 3차원 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# png 확장자의 이미지 데이터 다운로드 받기\n",
    "py_fpath = get_file('python.png','https://www.python.org/static/img/python-logo.png')\n",
    "image = Image.open(py_fpath)\n",
    "np.array(image).shape # 세번째 축의 원소의 개수가 RGBA 로 네가지이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image ## 투명한 부분이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.array(image)[40:41,20:21] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \\[ 2. DNN을 활용한 컴퓨터 비전 \\]\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 컴퓨터 비전(Computer Vision)\n",
    "\n",
    "---\n",
    "\n",
    "+ 기계의 시각에 해당하는 부분을 연구하는 컴퓨터 과학의 최신 연구 분야 중 하나\n",
    "+ 인간의 시각이 할 수 있는 몇 가지 일을 수행하는 자율적인 시스템을 만드는 것을 목표\n",
    "+ 예시) 이미지 분류, 물체인식, 얼굴인식, 물체추적, 이미지변환, 영상분할 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 심층신경망(DNN)을 활용한 컴퓨터 비전(?)\n",
    "\n",
    "---\n",
    "\n",
    "+ 0부터 9까지의 숫자를 손으로 작성한 `MINST` 이미지 데이터\n",
    "+ 손글씨 이미지 데이터를 입력받아 어떤 숫자를 쓴 이미지인지 분류하는 심층신경망(DNN) 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 손글씨 숫자 MNIST 데이터\n",
    "\n",
    "---\n",
    "\n",
    "![1_3](./img/1_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1. 손글씨 숫자 MNIST 데이터 가져오기\n",
    "\n",
    "`keras.datasets`에서 제공되는 `mnist` 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "trainset, testset = mnist.load_data()\n",
    "train_images, train_labels = trainset\n",
    "test_images, test_labels = testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 학습데이터의 개수와 모양\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 평가데이터의 개수와 모양\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# train_images[0,:,:] # 0부터 255까지의 숫자로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3. 이미지 데이터의 정규화\n",
    "(0\\~255)값의 색상값을 (0\\~1)의 범위로 변경\n",
    "\n",
    "* min-max 정규화란?  \n",
    "모델에 입력되는 데이터들의 값을 0~1 사이로 만들어 주어, 특정 데이터에 대해서만 강조되도록 학습하는 것이 아닌,  \n",
    "모든 데이터들에 대해서 균일하게 학습하도록 만드는 데이터 전처리 방식.\n",
    "\n",
    "공식: `(X - MIN) / (MAX-MIN)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 심층신경망(DNN) 모델 구성하기\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![1_4](./img/1_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28))\n",
    "\n",
    "flat = Flatten()(inputs) # x_1 ~ x_784\n",
    "dense1 = Dense(8, activation='relu')(flat)\n",
    "dense2 = Dense(8, activation='relu')(dense1)\n",
    "pred = Dense(10, activation='softmax')(dense2)\n",
    "\n",
    "model = Model(inputs, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 심층신경망 모델의 컴파일\n",
    "\n",
    "---\n",
    "\n",
    "+ 최적화함수 : `optimizer=\"sgd\"` 경사하강법\n",
    "+ 손실함수 : `loss = \"sparse_categorical_crossentropy\"` 교차엔트로피\n",
    "+ 평가방법 : `metrics = \"acc\"` 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  심층신경망 모델 학습진행\n",
    "---\n",
    "+ 배치 크기 : 64\n",
    "+ 학습횟수(epoch) : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_images, train_labels,\n",
    "                 batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습된 모델을 통한 추론\n",
    "\n",
    "학습된 모델 `model` 과 손글씨 이미지 데이터셋 `test_image`로 숫자 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples = test_images[:10]\n",
    "pred_probs = model.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred_label = np.argmax(pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "for idx, (image, label) in enumerate(\n",
    "    zip(samples, pred_label),1):\n",
    "    ax = fig.add_subplot(2,5,idx)\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")   \n",
    "    ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지를 심층신경망 모델로 했을 때의 문제점\n",
    "\n",
    "<img src=\"https://i.imgur.com/9Ax40I0.jpg\" width=\"800\">\n",
    "\n",
    "+ 파라미터의 수가 급격하게 증가 : <br>\n",
    "이미지의 크기에 따라 필요한 파라미터의 수가 기하급수적으로 증가<br>\n",
    "→ 메모리의 한계 문제 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### (예시_1) (64, 64) 크기의 영상에서 필요한 Parameter 수\n",
    "(64, 64)크기를 갖는 이미지 데이터를 유닛의 수가 100개인 `Dense` 층에 연결했을때 필요한 파라미터의 수?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# (64 , 64) 크기의 RGB 채널을 가진 영상\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "flat = Flatten()(inputs)\n",
    "out = Dense(100, activation='relu',use_bias=False)(flat)\n",
    "\n",
    "model = Model(inputs, out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### (예시_2) (1280, 720) 크기의 영상에서 필요한 Parameter 수\n",
    "(1280, 720)크기를 갖는 이미지 데이터를 유닛의 수가 100개인 `Dense` 층에 연결했을때 필요한 파라미터의 수?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(1280, 720, 3))\n",
    "\n",
    "flat = Flatten()(inputs)\n",
    "out = Dense(100, activation='relu',use_bias=False)(flat)\n",
    "\n",
    "model = Model(inputs, out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [ 3. 동물의 사물 인지와 컴퓨터 비전 ]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 동물이 사물을 인지하는 방법\n",
    "\n",
    "---\n",
    "\n",
    "![1_5](./img/1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지의 특징\n",
    "\n",
    "---\n",
    "\n",
    "+ 간단한 특징들을 조합하여 점점 복잡한 특징을 표현할 수 있음\n",
    "\n",
    "![1_6](./img/1_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4. 합성곱신경망을 이용한 컴퓨터 비전 ]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "\n",
    "conv1 = Conv2D(128,3,activation=\"relu\")(inputs) ## 단 8개의 필터로 구성된 CNN\n",
    "pool1 = MaxPooling2D()(conv1)\n",
    "conv2 = Conv2D(128,3,activation=\"relu\")(pool1)\n",
    "pool2 = MaxPooling2D()(conv2)\n",
    "\n",
    "flat = Flatten()(pool2)\n",
    "pred = Dense(10, activation='softmax')(flat)\n",
    "\n",
    "model = Model(inputs, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples = test_images[:10]\n",
    "pred_probs = model.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred_label = np.argmax(pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "for idx, (image, label) in enumerate(\n",
    "    zip(samples, pred_label),1):\n",
    "    ax = fig.add_subplot(2,5,idx)\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")   \n",
    "    ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() ## 압도적인 파라미터의 수 감축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `이미지 데이터와 컴퓨터 비전의 이해` 마무리\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### references\n",
    "\n",
    "+ Deep Learning - Ian Goodfellow [deeplearningbook.org/](https://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../../src/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# \\[부록 컨텐츠\\]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확장자별 이미지 데이터의 차이\n",
    "\n",
    "`png`, `gif`, `jpg`, `tif`의 차이"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
