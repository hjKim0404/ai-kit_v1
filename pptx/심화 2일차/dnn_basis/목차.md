01. 딥러닝(Deep Learning)은 무엇인가
    > 목표 : 1. 딥러닝이 대강 이런 걸 하는 구나. 2. 딥러닝에는 이런거구나.
    + 인공지능이란
    + 머신러닝 프로그래밍이란
    + 머신러닝으로 무엇을 할 수 있을까 <- 여기서 지도/비지도와 함께 분류, 군집화, 회귀
    + 딥러닝이란
    + 딥러닝 맛보기 <- mnist, 예측, 분류 등등에 대해 Input(데이터), Output(결과)만 보여주기
    
02. 딥러닝 프레임워크, 케라스의 필요성
    > 딥러닝을 위한 종합적인 복습 + 잡다구리한것들 모두 알고가기
    > 목표 : 1. 아 이래서 케라스가 필요하구나 2. 선형회귀가 이런거였지.
    + 예측문제 <- 데이터가 흩뿌려져 있다. 그런데 모르는 위치가 있다. 그때 결과를 알고싶다.
    + 선형회귀 <- 대강 직선을 이렇게 그리면 어느정도 맞지 않을까.
    + 선형회귀의 결과 <- 결과로 예측값이 나온다. 근데 잘 예측하고싶다.
    
    + 학습 <- 손실함수, 그리드서치, 그래디언트 디센트, 내용 다 빠르게
    + 손실함수 <- 예측값과 실제값의 차이가 작다면 잘 예측한것. 그런 weight를 찾고자한다. 어떻게?
    + 그리드 서치 <- 이걸로는 안된다. 우리의 문제는 "손실함수가 최소이길 바라"
    + 그래디언트 디센트 <- 기울기가 낮은쪽으로 이동시켜가며 찾자.근데 미분이 필요하다. 어떻게 하지
    + 딥러닝 프레임워크 <- 미분해주는 텐서플로우가 있지.
    + 그래서 이후로는 케라스 쓴다는 이야기
    
  
    
03. 퍼셉트론과 신경망의 표현과 구현
    > 목표 : 1. 딥러닝은 이렇게 구성되어있구나. 2. 케라스로는 이렇게 신경망을 구현하는 구나. 3. 이렇게 표현하는구나
    + 가장 작은 신경망, 퍼셉트론
    + 생물의 뉴런과 딥러닝의 퍼셉트론
        + 앞에서 배운 선형회귀와 퍼셉트론 차이
    + 퍼셉트론의 활성화함수 <- 시그모이드와 렐루, 그리고 왜 필요한지 설명

    + 신경망(Neural Network)의 표현과 구현
    + 한개의 퍼셉트론 구현하기
    + 세개의 퍼셉트론 구현하기 <- 여기서 "유닛이 여러개 모인 것이 바로 '인공 신경망'입니다. 
    + 2층 신경망의 표현과 구현
    + 5층 신경망의 표현과 구현
    + 다중 출력 신경망의 표현과 구현
    + 쌓아서 생기는 이점
    
    + 신경망의 구성요소와 표현
    + 층과 유닛
    + 가중치와 편향

04. 신경망의 순전파
    > 목표 : 1. 딥러닝은 입력과 가중치를 가지고 이렇게 결과를 계산해내는 구나
    + 순전파
    + 유닛단위의 순전파 <- 회귀가 쓰였지여 언급
    + 층 단위의 순전파 <- 이렇게 저렇게 연결연결 수식으로 표현
    + 순전파의 설계 - 케라스
    + 순전파의 실행 - 넘파이

5. 신경망의 학습

   > 목표 : 1. 각 유닛에서 기울기를 찾아야 하는구나. 2. 그거 찾는거 연산식이 너무 복잡하고 어렵구나. 3. 연쇄법칙이 있으면 해결해 주는구나

   + 선형회귀로 이해하는 학습 <- 다시 선형회귀로 넘어가 봅시다.
   + 손실함수 <- 우리는 예측과 결과의 차이를 줄이고 싶다. 어떻게?
   + 최적화함수 <- 기울기만큼을 빼주면 최소값에 다다른다.
   + 각 유닛(퍼셉트론)도 회귀처럼 학습할거다

   + 신경망에서의 학습
   + 신경망에서 그래디언트 <- 그걸한번 신경망에 적용하면 ~를 계산해야한다.
   + 역전파가 왜 필요할까 <- 이거를 다 계산해줘야 풀 수 있다.
   + 연쇄법칙 <- 연쇄법칙을 이용하면 이렇게 식이 줄어든다. ( 뒤로 보내면 어떨까 합니다. )

6. 신경망의 역전파

   > 목표 : 1. 각 연산에서 역전파는 이렇게 계산되는구나

   + 계산그래프
   + 계산그래프에서의 순전파
   + 우리는 이 계산그래프에서 앞으로 보내지는 미분값을 얻어야 한다. 잠시 미분을 보고가자
   + 여러가지 미분 법칙
   + 편미분 
   + 덧셈/곱셈/행렬곱 역전파 : 미분법칙
   + 원하는 그래디언트 : 연쇄법칙
   + 원하는 그래디언트 : 편미분
   + 활성화함수의 역전파
   + 손실함수의 역전파

7. 프로젝트 : 정형데이터를 활용한 이진분류 인공지능 만들기

   + 그대로

8. 프로젝트 : 이미지를 분류하는 인공지능 만들기

   + 그대로