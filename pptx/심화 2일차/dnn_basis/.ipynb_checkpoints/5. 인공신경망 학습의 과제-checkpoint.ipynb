{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**_심층신경망(DNN) 기본기_**\n",
    "\n",
    "\n",
    "# 5. 인공신경망 학습의 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### _Objective_\n",
    "\n",
    "1. 선형회귀모델에서의 학습을 다시 살펴보며 `\"모델의 학습\"`이 어떤 의미인지 상기합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. 인공신경망이 학습되는 과정에서 `그래디언트(Gradient)`가 무엇인지 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. 인공신경망의 학습에서 안고있는 과제를 이해하고 어떻게 해결할 수 있을지 생각해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 필요한 패키지 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이에서의 소숫점을 넷째자리수까지만 표기\n",
    "np.set_printoptions(precision=5,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화시 한글 폰트 설정을 위한 패키지\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# plt 폰트 설정\n",
    "\n",
    "fm._rebuild() # 폰트 관련 캐시 삭제\n",
    "font_fname = '../../src/d2coding.ttf'\n",
    "font_family = fm.FontProperties(fname=font_fname).get_name()\n",
    "\n",
    "plt.rcParams[\"font.family\"] = font_family\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [1. 선형회귀에서의 학습(Learning)]\n",
    "\n",
    "---\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 인공지능 모델의 학습\n",
    "\n",
    "---\n",
    "\n",
    "`인공지능 모델의 학습`은\n",
    "1. 피쳐가 주어졌을 떄 모델이 목적을 잘 수행하도록 모델의 파라미터를 수정하는 것이다.\n",
    "2. 학습 모델은 학습 알고리즘과 학습 데이터를 통해 스스로 파라미터를 수정한다.\n",
    "3. 모델의 결과가 인간의 결과와의 차이가 더욱 적게 나는 방향으로 학습을 수행한다.\n",
    "\n",
    "![6_1](./img/6_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [예제] 머신러닝의 기초, 선형회귀 모델에서의 학습\n",
    "\n",
    "---\n",
    "\n",
    "1. 예측값 $\\hat{y} = \\beta_1 x + \\beta_0$ 의 가장 단순한 선형회귀 모델\n",
    "2. 주어진 데이터(`x에 따른 y`)를 가장 잘 설명하는 $\\beta_1$과 $\\beta_0$를 찾기\n",
    "3. `모델의 예측이 사람과 다른 정도`를 어떻게 나타내는지, 어떻게 줄여나가는지 이해\n",
    "\n",
    "![5_1](./img/5_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 문제 정의 : 주어진 데이터와 얻고자 하는 정보\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "+ 왓챠에서 제공하는 “보고싶어요” 수와 관객 수 간의 관계를 바탕으로 영화 “옥자”의 예상 관객 수 예측하기\n",
    "\n",
    "![5_2](./img/5_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "movie_1 = pd.Series({\"num_want_to_see\": 8759,  \"nums_audience\": 487 }, name=\"마션\")\n",
    "movie_2 = pd.Series({\"num_want_to_see\": 10132, \"nums_audience\": 612 }, name=\"킹스맨\")\n",
    "movie_3 = pd.Series({\"num_want_to_see\": 12078, \"nums_audience\": 866 }, name=\"캡틴아메리카\")\n",
    "movie_4 = pd.Series({\"num_want_to_see\": 16430, \"nums_audience\": 1030}, name=\"인터스텔라\")\n",
    "movie_df = pd.DataFrame([movie_1, movie_2, movie_3, movie_4])\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형회귀 모델링 : 입력값과 출력값 정의\n",
    "\n",
    "---\n",
    "\n",
    "실측값(Ground Truth)으로 입력값 $x$에 따른 예측값$\\hat{y}$을 내는 선형회귀 모델을 생성\n",
    "\n",
    "![5_3](./img/5_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = movie_df[\"num_want_to_see\"] ##\n",
    "y = movie_df[\"nums_audience\"] ##\n",
    "input_x = 12008 ## 입력값 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"영화 '보고싶어요 수'에 따른 '총 관객수'\")\n",
    "plt.xlabel(r\"피쳐($x$): 보고싶어요 수(명)\")\n",
    "plt.ylabel(r\"라벨($y$): 총 관객 수(만명)\"); \n",
    "\n",
    "plt.scatter(x,y, label=\"실측값\") ## x,y 만 지우고 타이핑\n",
    "plt.axvline(input_x, lw=1, ls=\"--\", c=\"C1\", label=\"예측 입력값\") ## input_x만 지우고 타이핑\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```python\n",
    "\"\"\"\n",
    "여기서, \n",
    "+ $x$를 피쳐(feature), $y$를 레이블(Label)\n",
    "+ 주어진 데이터; $x,y$를 실측값(Ground Truth)라 한다.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 선형회귀 모델링 : 선형회귀 정의\n",
    "\n",
    "---\n",
    "\n",
    "`입력값`($x$; feature)에 따른 `출력값`($\\hat{y}$; prediction value, 예측값)의 관계를 선형회귀로 정의하기\n",
    "\n",
    "![5_4](./img/5_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 가중치 $a$, $b$에 따른 선형회귀 추세선 확인\n",
    "모델링에 따라 다양한 가능한 가중치의 조합이 존재\n",
    "* $a=0.05, b= 100$일때, $\\hat y_{red} = 0.05x+100$\n",
    "* $a=0.08, b=-240$일때, $\\hat y_{green} = 0.08x-240$\n",
    "* $a=0.12, b=-600$일때, $\\hat y_{blue} = 0.12x-600$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 선형방정식 예시\n",
    "model_red = lambda x: 0.05*x + 100\n",
    "model_green = lambda x: 0.08*x - 240\n",
    "model_blue = lambda x: 0.12*x - 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![5_5](./img/5_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 각 회귀모델의 \"총 관객수\" 예측값\n",
    "\n",
    "입력값($x$) = 영화 \"옥자\"의 \"보고싶어요 수(명)\" : 12008명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input_x = 12008\n",
    "\n",
    "y_blue = model_blue(input_x)\n",
    "y_green = model_green(input_x)\n",
    "y_red = model_red(input_x)\n",
    "\n",
    "print(y_blue)\n",
    "print(y_green)\n",
    "print(y_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![5_7](./img/5_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\" ※ 이 때, 어떤 추세선이 더 잘 예측하는지 기준이 필요 \"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 손실값(Loss)과 손실함수(Loss Function)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "1. \"모델이 잘 예측한다.\" → \"모델의 예측값과 실측값의 차이가 적다.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. \"예측값과 실측값에 차이가 나는 정도\" 기준 → `손실(Loss)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. 예측값과 실측값으로 손실을 계산하는 함수 → `손실함수(Loss Function)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "![5_8](./img/5_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "( ※ 손실값(Loss)는 더 넓은 의미로 비용(Cost) 라고도 부른다. <br>\n",
    "이 때, 비용을 계산하는 함수를 비용함수(Cost Function)라고 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 손실함수: 평균제곱오차(MSE; Mean Squared Error)\n",
    "\n",
    "---\n",
    "\n",
    "실측값 $y$와 예측값 $\\hat{y}$에 대해<br>\n",
    "모델의 예측값과 실측값의 차이 ($y - \\hat{y}$) → `오차(Error)`\n",
    "\n",
    "$$평균제곱오차\\; MSE = \\frac{1}{n}\\sum_{i=1}^{n}( y_i - \\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![5_9](./img/5_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 선형회귀 모델의 예측값 $\\hat{y}$ 계산\n",
    "실측값에서의 각 피쳐 $x$에 대한 모델의 예측값 $\\hat{y} = w_1 x + w_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 피쳐 x에 대한 각 모델별 예측값\n",
    "\n",
    "y_pred_blue = model_blue(x.values)\n",
    "y_pred_red = model_red(x.values)\n",
    "y_pred_green = model_green(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred_df = movie_df.assign(pred_blue = y_pred_blue, pred_red = y_pred_red, pred_green = y_pred_green)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 각 예측값 $\\hat{y}$ 의 오차 (Error) 계산\n",
    "실측값에서의 각 라벨 $y$와 예측값 $\\hat{y}$의 오차 $\\text{Error} = y - \\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "error_blue = y - y_pred_blue\n",
    "error_red = y - y_pred_red\n",
    "error_green = y - y_pred_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pred_df = pred_df.assign(error_blue = error_blue, error_red = error_red, error_green = error_green)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 평균제곱오차(MSE) 계산\n",
    "$\\text{평균제곱오차} MSE = \\frac{1}{n}\\sum(Error)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. 오차 ($y-\\hat{y}$) 는 음(-)의 값이 나올 수 있다. → 제곱하여 양수로 바꾸어 줌 : $(y-\\hat{y})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. 다수의 데이터에 대한 모델의 오차 : 오차들의 합 SSE(Sum of Error) $\\sum(y- \\hat{y})^2$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. SSE는 데이터가 많을수록 커진다. → 각 데이터의 오차를 평균 $\\frac{1}{n}\\sum(y-\\hat{y})^2$<br>\n",
    "(비교하는 데이터의 개수와는 별개로 손실값을 계산하고자 한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# MSE 계산\n",
    "mse_blue = (error_blue**2).mean()\n",
    "mse_red = (error_red**2).mean()\n",
    "mse_green = (error_green**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(mse_blue)\n",
    "print(mse_red)\n",
    "print(mse_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_10](./img/5_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\" ※ 목적 :  손실값 MSE를 최소화하는 최소화하는 모델을 찾는다. \" : 최적화 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적화(Optimization)\n",
    "\n",
    "---\n",
    "입력값 $x$, 함수의 파라미터 $w$, 함수의 결과 $f(x; w)$일때,<br> \n",
    "\n",
    "`최적화(Optimization)` : 함수 $f$의 결과 $f(x; w)$를 최대화 또는 최소화 하는 파라미터 $w$를 찾는 문제\n",
    "\n",
    "\n",
    "( ⚠︎ 수학적 최적화 정의 [ko.wikipedia.org/wiki/수학적_최적화](https://ko.wikipedia.org/wiki/%EC%88%98%ED%95%99%EC%A0%81_%EC%B5%9C%EC%A0%81%ED%99%94) 에서 머신러닝 학습의 이해를 돕기 위한 설명 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 파라미터와 함수의 정의\n",
    "머신러닝의 학습에서 최적화의 대상이 되는 함수, 손실함수<br>\n",
    "$\\hat{y} = ax+b$ 일때, $\\text{평균제곱오차} MSE = \\frac{1}{n}\\sum(\\hat{y_i} - y_i)^2 = \\frac{1}{n}\\sum(ax_i+b - y_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mse = lambda x,y,a,b: ((a*x + b - y)**2).mean()\n",
    "\n",
    "# 예컨데, a=0.1, b=-100에서\n",
    "mse(x,y,a=0.1,b=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "이 때, 실측값($x,y$)는 정해져 있으므로 MSE는 ($a, b$)의 값에 따라 결정된다.\n",
    "\n",
    "즉, 손실함수 Loss(x; w)에서 머신러닝 모델의 최적화 → 손실함수를 최소화 하는 w의 값을 찾기 $\\underset{a, b}{\\text{minimize}} \\; Loss(a,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_11](./img/5_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 최적의 a, b의 값을 찾는 방법, 그리드서치(?)\n",
    "\n",
    "`그리드서치(Grid Search)`:  가능한 ($a, b$)의 조합으로 손실값을 계산하여 최소가 되는 ($a, b$) 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_case = np.linspace(-1, 1, 100) # 100가지 경우\n",
    "b_case = np.linspace(-1000, 1000, 100) # 100가지 경우\n",
    "\n",
    "# 가능한 모든 a, b 조합\n",
    "a_b_cases = np.stack(np.meshgrid(a_case,b_case), axis=-1).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 모든 경우의 a, b에서 Loss 값 계산하기\n",
    "losses = []\n",
    "for a, b in a_b_cases:\n",
    "    loss = mse(x,y,a,b)\n",
    "    losses.append(loss)\n",
    "losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# loss를 최소화 하는 a, b의 값\n",
    "optim_a, optim_b = a_b_cases[np.argmin(losses)]\n",
    "optim_y = optim_a * input_x + optim_b\n",
    "print(f\"손실을 최소화하는 최적의 a 값 : {optim_a:.5f}\")\n",
    "print(f\"손실을 최소화하는 최적의 b 값 : {optim_b:.5f}\")\n",
    "print(f\"a, b 파라미터의 선형회귀 모델로 예측한 옥자 총 관객수 : {optim_y:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "x_extent = np.linspace(9000,16000)\n",
    "y_linear = optim_a * x_extent + optim_b\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"영화 '보고싶어요 수'에 따른 '총 관객수'\")\n",
    "plt.xlabel(r\"피쳐($x$): 보고싶어요 수(명)\")\n",
    "plt.ylabel(r\"라벨($y$): 총 관객 수(만명)\"); \n",
    "\n",
    "plt.scatter(x,y, label=\"실측값\")\n",
    "plt.scatter(input_x, optim_y, c=\"C1\", label=\"옥자 예측값\")\n",
    "plt.axvline(input_x, lw=1, ls=\"--\", c=\"C1\", label=\"예측 입력값\")\n",
    "plt.plot(x_extent,y_linear, label=\"선형회귀모델\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터 a, b에 따른 Loss 값 시각화\n",
    "mse_cases = np.concatenate([a_b_cases, losses.reshape(-1,1)], axis=-1)\n",
    "mse_cases = mse_cases.reshape(100,100,3)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.gca(projection='3d')\n",
    "ax.plot_surface(X=mse_cases[:,:,0],\n",
    "                Y=mse_cases[:,:,1],\n",
    "                Z=mse_cases[:,:,2],\n",
    "                cmap=cm.coolwarm)\n",
    "ax.set_xlabel('파라미터 a')\n",
    "ax.set_ylabel('파라미터 b')\n",
    "ax.set_zlabel('손실값 Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "\"※ 하지만, 파라미터의 모든 경우를 고려하기에는 연산량이 지나치게 많아진다.\" \n",
    "→ 수학적으로 최적화하는 알고리즘이 필요 : 최적화함수\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 만약 파라미터의 수가 5개이고, 각각 100가지 경우만 고려하여 손실을 계산한다고 해도\n",
    "100**5 # 총 100억가지 경우의 수가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적화함수(Optimizer)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "최적화 함수  : 현재의 파라미터에서 더 최적화된 방향으로 파라미터를 갱신하는 방법<br>\n",
    "대표적인 최적화 함수, `경사하강법(Gradient Descent; 그래디언트 디센트)` : \n",
    "\n",
    "$w := w - \\gamma \\frac{\\partial Loss}{\\partial w}$\n",
    "\n",
    "\n",
    "( 위키피디아의 경사하강법 정의 [ko.wikipedia.org/wiki/경사_하강법](https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_12](./img/5_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_13](./img/5_13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_14](./img/5_14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_15](./img/5_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_16](./img/5_16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_17](./img/5_17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_18](./img/5_18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_19](./img/5_19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 경사하강법 (Gradient Descent)\n",
    "\n",
    "$m$개의 데이터에서 모델($ax + b$)의 손실(Loss)이<br>\n",
    "$\\text{평균제곱오차} MSE =  \\frac{1}{m}\\sum(ax^{(i)}+b - y^{(i)})^2$일때,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "model = lambda x,a,b: a*x+b\n",
    "mse = lambda pred, true: ((pred - true)** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 무작위로 현재 파라미터를 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 무작위로 현재의 파라미터 a가 -0.75, b가 -100라고 한다면\n",
    "a = -0.75\n",
    "b = -100\n",
    "\n",
    "# 현재의 Loss값\n",
    "model(x,a,b)\n",
    "y_pred = model(x,a,b)\n",
    "mse(y_pred,y)\n",
    "loss = mse(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 그래디언트(Gradient)의 계산\n",
    "\n",
    "$Loss =  \\frac{1}{m}\\sum(ax^{(i)}+b - y^{(i)})^2$일때, 파라미터 $a$, $b$의 그래디언트:<br>\n",
    "$$\\frac{\\partial Loss}{\\partial a} = \\frac{1}{m}\\sum_{i=1}^{m}(ax^{(i)}+b - y^{(i)})x^{(i)}$$<br>\n",
    "$$\\frac{\\partial Loss}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}(ax^{(i)}+b - y^{(i)})$$\n",
    "\n",
    "( ※ 미분 법칙 중 \"선형성\", \"곱의 법칙\", \"연쇄법칙\" 참조 : [ko.wikipedia.org/wiki/미분법](https://ko.wikipedia.org/wiki/%EB%AF%B8%EB%B6%84%EB%B2%95) )<br>\n",
    "( ⚠︎ 여기서, 그래디언트의 상수곱은 무시하였다. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "derivative_a = lambda x,y,a,b : ((a*x + b - y)*x).mean()\n",
    "derivative_b = lambda x,y,a,b : (a*x + b - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gradient_a = derivative_a(x,y,a,b)\n",
    "gradient_b = derivative_b(x,y,a,b)\n",
    "\n",
    "gradient_a, gradient_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 러닝레이트($\\gamma$; learning rate)\n",
    "\n",
    "파라미터의 갱신(Update)에서,<br>\n",
    "$a_{new} := a_{old} - \\gamma \\frac{\\partial Loss}{\\partial a}$ , \n",
    "$b_{new} := b_{old} - \\gamma \\frac{\\partial Loss}{\\partial b}$\n",
    "\n",
    "러닝레이트 $\\gamma$ 를 결정해야 하는 이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터를 갱신하기 전\n",
    "\n",
    "loss_old = mse(model(x,a,b), y)\n",
    "print(f\"갱신 전 손실 MSE : {loss_old}\") # 손실값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"파라미터 a, b : {a}, {b}\") # 파라미터\n",
    "print(f\"그래디언트 d_a, d_b : {gradient_a}, {gradient_b}\") # 그래디언트\n",
    "## 파라미터에 비해 그래디언트의 값이 지나치게 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**러닝레이트가 0.001이라면**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 러닝레이트가 0.001 이라면\n",
    "lr = 0.001\n",
    "gradient_a * lr, gradient_b * lr ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터 갱신\n",
    "print(a, b) ##\n",
    "a_new = a - lr * gradient_a ##\n",
    "b_new = b - lr * gradient_b ##\n",
    "\n",
    "\n",
    "a, b ##\n",
    "a_new, b_new ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터를 갱신한 후의 손실\n",
    "\n",
    "loss_new = mse(model(x,a_new,b_new), y)\n",
    "print(f\"갱신 전 손실 MSE : {loss_old}\")\n",
    "print(f\"갱신 후 손실 MSE : {loss_new}\")\n",
    "## 손실값이 되려 더 커졌다. 더욱 적절한 러닝레이트를 찾아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\"※ 너무 큰 러닝레이트는 손실을 오히려 증가시킨다.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**러닝레이트가 1e-12 이라면**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 러닝레이트가 0.000000000001 이라면\n",
    "lr = 1e-12\n",
    "gradient_a * lr, gradient_b * lr ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터 갱신\n",
    "a_new = a - lr * gradient_a\n",
    "b_new = b - lr * gradient_b\n",
    "\n",
    "a, b ##\n",
    "a_new, b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터를 갱신한 후\n",
    "\n",
    "loss_new = mse(model(x,a_new,b_new), y)\n",
    "print(f\"갱신 전 손실 MSE : {loss_old}\")\n",
    "print(f\"갱신 후 손실 MSE : {loss_new}\")\n",
    "## 손실값에 차이를 너무 조금밖에 주지 못했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\"※ 너무 작은 러닝레이트는 손실을 너무 적게 변화시킨다.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**러닝레이트가 2e-10 이라면**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr = 2e-10\n",
    "gradient_a * lr, gradient_b * lr ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터 갱신\n",
    "a_new = a - lr * gradient_a\n",
    "b_new = b - lr * gradient_b\n",
    "\n",
    "a, b ##\n",
    "a_new, b_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터를 갱신한 후\n",
    "\n",
    "loss_new = mse(model(x,a_new,b_new), y)\n",
    "print(f\"갱신 전 손실 MSE : {loss_old}\")\n",
    "print(f\"갱신 후 손실 MSE : {loss_new}\")\n",
    "\n",
    "## 확실히 줄었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "\"※ 실험을 통해 적절한 러닝레이트를 찾아야 함.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 에폭(epoch)의 결정\n",
    "\n",
    "데이터셋 전체를 모델의 학습에 사용한 횟수 : `에폭(epoch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 만약, 데이터를 300번 사용하여 학습할 경우\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 모델 학습\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 학습 진행하기\n",
    "\n",
    "---\n",
    "\n",
    "지금까지 결정된 하이퍼파라미터(hyper parameter)를 통해 선형회귀 모델을 학습\n",
    "\n",
    "실측값 : ($x, y$), 예측값 : $\\hat{y}$, 파라미터 : $a, b$<br>\n",
    "모델 : $\\hat{y} = ax + b$<br>\n",
    "손실함수 :  MSE = $\\frac{1}{n}\\sum_{i=1}^{n}( y_i - \\hat{y}_i)^2$<br>\n",
    "최적화함수 경사하강법 : $w := w - \\gamma \\frac{\\partial Loss}{\\partial w}$<br>\n",
    "러닝레이트 : $\\gamma$ = 2e-10<br>\n",
    "에폭 : 300회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 기록 \n",
    "# 현재의 파라미터와 손실값으로 0번째 학습 기록\n",
    "a_history = [a]\n",
    "b_history = [b]\n",
    "loss_history = [loss]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # 갱신 전 파라미터\n",
    "    a_old = a_history[-1]\n",
    "    b_old = b_history[-1]\n",
    "    \n",
    "    # 예측값 도출(순전파)\n",
    "    y_pred = model(x,a_old,b_old)\n",
    "    \n",
    "    # 그래디언트 계산\n",
    "    gradient_a = ((y_pred - y)*x).mean()\n",
    "    gradient_b = ((y_pred - y)).mean()\n",
    "    \n",
    "    # 경사하강법을 통한 파라미터 갱신\n",
    "    a_new = a_old - lr * gradient_a\n",
    "    b_new = b_old - lr * gradient_b\n",
    "    \n",
    "    # 현 시점의 손실값 계산\n",
    "    loss_new = mse(y_pred,y)\n",
    "    \n",
    "    \n",
    "    # 결과 저장\n",
    "    a_history.append(a_new)\n",
    "    b_history.append(b_new)\n",
    "    loss_history.append(loss_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결과 확인하기\n",
    "\n",
    "---\n",
    "\n",
    "`a_history`, `b_history`, `loss_history` 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame({\n",
    "        \"a\":a_history,\n",
    "        \"b\":b_history,\n",
    "        \"loss\":loss_history\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 손실값 확인을 통한 학습 진행 경과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "history_df.plot(y='loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 학습에 따른 파라미터의 변화 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 최종적으로 학습된 파라미터\n",
    "print(f\"a : {a_new}\")\n",
    "print(f\"b : {b_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 파라미터 a, b에 따른 Loss 값 시각화\n",
    "mse_cases = np.concatenate([a_b_cases, losses.reshape(-1,1)], axis=-1)\n",
    "mse_cases = mse_cases.reshape(100,100,3)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.gca(projection='3d')\n",
    "\n",
    "ax.scatter(history_df[\"a\"], \n",
    "           history_df[\"b\"], \n",
    "           history_df[\"loss\"],\n",
    "           c='r', \n",
    "           label=\"파라미터 변화\")\n",
    "\n",
    "ax.plot_surface(X=mse_cases[:,:,0],\n",
    "                Y=mse_cases[:,:,1],\n",
    "                Z=mse_cases[:,:,2],\n",
    "                cmap=cm.coolwarm,alpha=0.5)\n",
    "ax.set_xlabel('파라미터 a')\n",
    "ax.set_ylabel('파라미터 b')\n",
    "ax.set_zlabel('손실값 Loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 최적화된 모델을 통한 예측\n",
    "\n",
    "![5_2](./img/5_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_new = input_x * a_new + b_new\n",
    "\n",
    "print(f\"학습된 파라미터 a : {a_new:.5f}\")\n",
    "print(f\"학습된 파라미터 b : {b_new:.5f}\")\n",
    "print(f\"학습된 선형회귀 모델로 예측한 옥자 총 관객수 : {y_new:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "x_extent = np.linspace(9000,16000)\n",
    "y_linear = a_new * x_extent + b_new\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"영화 '보고싶어요 수'에 따른 '총 관객수'\")\n",
    "plt.xlabel(r\"피쳐($x$): 보고싶어요 수(명)\")\n",
    "plt.ylabel(r\"라벨($y$): 총 관객 수(만명)\"); \n",
    "\n",
    "plt.scatter(x,y, label=\"실측값\")\n",
    "plt.scatter(input_x, y_new, c=\"C1\", label=\"옥자 예측값\")\n",
    "plt.axvline(input_x, lw=1, ls=\"--\", c=\"C1\", label=\"예측 입력값\")\n",
    "plt.plot(x_extent,y_linear, label=\"학습된 선형회귀모델\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [2. 인공신경망에서의 학습(Learning)]\n",
    "\n",
    "---\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 인공신경망에서의 학습\n",
    "\n",
    "---\n",
    "\n",
    "모델의 순전파 결과 $\\hat{y}$와 실측값 $y$로 계산된\n",
    "손실값 $Loss$로 각 레이어에서의 가중치 $W^{[l]}, b^{[l]}$ 을 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "fpath = get_file(\"cancer_dataset.csv\",\n",
    "                 \"https://s3.ap-northeast-2.amazonaws.com/pai-datasets/alai-deeplearning/cancer_dataset.csv\")\n",
    "cancer_df = pd.read_csv(fpath)\n",
    "\n",
    "# 피쳐(feature) X, 라벨(label) y\n",
    "\n",
    "X = cancer_df[['age','tumor_size']]\n",
    "y = cancer_df[\"label\"]\n",
    "\n",
    "X = (X - X.min()) / (X.max() - X.min()) # 피쳐(feature) X의 min-max 정규화\n",
    "y = y.values.reshape(-1,1) # 라벨 y를 입력 가능한 형태로 모양변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 인공신경망의 순전파를 통한 예측\n",
    "\n",
    "![5_23](./img/5_23.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(2)\n",
    "dense_1 = Dense(3,\"relu\")(inputs)\n",
    "dense_2 = Dense(3, \"relu\")(dense_1)\n",
    "outputs = Dense(1, \"sigmoid\")(dense_2)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X) # 순전파 진행\n",
    "y_pred = model.predict(X) # 순전파 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 예측값과 실측값에 의한 손실 Loss 값 계산\n",
    "\n",
    "모델의 순전파 결과 $\\hat{y}$와 실측값 $y$로 계산된\n",
    "손실값 $Loss$\n",
    "\n",
    "![5_20](./img/5_20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 평균제곱오차 MSE\n",
    "loss = ((y_pred - y)**2).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 인공신경망에서의 경사하강법\n",
    "\n",
    "학습이 진행될 대상 : 각 레이어간 유닛의 가중치 $W, b$ \n",
    "\n",
    "![5_21](./img/5_21.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 각 레이어에서의 가중치 확인\n",
    "model.layers[1].weights # 업데이트 대상\n",
    "## 1, 2, 3 바꾸어가며 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 경사하강법에 필요한 그래디언트\n",
    "\n",
    "각 가중치를 업데이트하기 위해 계산해야할 그래디언트 $\\frac{\\partial Loss}{\\partial W}$\n",
    "\n",
    "![5_22](./img/5_22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf.Variable([1]).assign_sub([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 경사하강법\n",
    "# 알아야 하는 값, gradient = ???\n",
    "\n",
    "# for layer in model.layers[1:]:\n",
    "#     layer.weight[0].assign_sub(lr * ???)\n",
    "#     layer.weight[1].assign_sub(lr * ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 그래디언트의 계산 ( 수식을 전개 했을 경우 ) \n",
    "\n",
    "---\n",
    "\n",
    "그래디언트 $\\frac{\\partial Loss}{\\partial W}$, $\\frac{\\partial Loss}{\\partial b}$ 을 계산하는 미분 수식을 전개하여 필요한 연산 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 예시) $w^{[1]}_{11}$ 의 업데이트를 위해 필요한 그래디언트,  $\\frac{\\partial Loss}{\\partial w^{[1]}_{11}}$ 의 계산\n",
    "\n",
    "![5_24](./img/5_24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1. 미분의 연쇄 법칙을 활용한 합성함수의 미분 전개\n",
    "\n",
    "![5_25](./img/5_25.png)\n",
    "\n",
    "미분의 연쇄법칙 : [ko.wikipedia.org/wiki/연쇄_법칙](https://ko.wikipedia.org/wiki/%EC%97%B0%EC%87%84_%EB%B2%95%EC%B9%99) : $\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial u}\\cdot \\frac{\\partial u}{\\partial x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. 미분의 연쇄법칙을 활용한 선형결합 미분 전개\n",
    "\n",
    "다음 레이어의 각 유닛에서의 선형결합 $z_i^{[l]} = w_{1i}^{[l+1]}a_1^{[l]} + w_{2i}^{[l+1]}a_2^{[l]} + w_{3i}^{[l+1]}a_3^{[l]} + b_i^{[l+1]}$에 대한 미분 전개<br>\n",
    "\n",
    "\n",
    "\n",
    "![5_26](./img/5_26.png)\n",
    "\n",
    "\n",
    "다변수함수의 연쇄법칙 [wikipedia.org/wiki/연쇄_법칙](https://ko.wikipedia.org/wiki/%EC%97%B0%EC%87%84_%EB%B2%95%EC%B9%99) : $\\frac{\\partial f}{\\partial x_j} = \\frac{\\partial f}{\\partial u_1}\\frac{\\partial u_1}{\\partial x_j} + \\frac{\\partial f}{\\partial u_2}\\frac{\\partial u_2}{\\partial x_j} + ... + \\frac{\\partial f}{\\partial u_m}\\frac{\\partial u_m}{\\partial x_j}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![5_27](./img/5_27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3. 동일한 방법으로 마지막 레이어까지 연쇄법칙 적용\n",
    "\n",
    "![5_28](./img/5_28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 인공신경망 학습의 과제 \n",
    "\n",
    "---\n",
    "\n",
    "인공신경망의 학습에 필요한 각 가중치에서의 그래디언트의 문제점과 해결 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 복잡한 그래디언트 계산\n",
    "\n",
    "![5_29](./img/5_29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 역전파의 아이디어\n",
    "\n",
    "![5_30](./img/5_30.png)\n",
    "\n",
    "$w^{[1]}_{11}$의 그래디언트 계산에는 $w_{31}^{[3]}$의 값과 $w_{31}^{[3]}$의 그래디언트 계산에 필요한 연산이 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 역전파의 아이디어\n",
    "![5_31](./img/5_31.png)\n",
    "\n",
    "\n",
    "전방 레이어(입력층 방향)의 가중치에 대한 그래디언트 계산 수식에는 <br>\n",
    "후방 레이어(출력층 방향)의 가중치에 대한 그래디언트 계산 수식에서 중복으로 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 역전파의 아이디어\n",
    "\n",
    "이미 계산된 미분값을 저장한 후 이를 재사용\n",
    "\n",
    "\n",
    "1. 순전파 진행시, 손실값이 필요하지 않은 미분값을 미리 계산 후 저장\n",
    "2. 순전파를 통해 계산된 예측값과 실측값으로 손실값 Loss 계산\n",
    "3. 출력에서 입력 방향으로 Loss에 대한 미분값을 연산하며 필요한 그래디언트 계산\n",
    "\n",
    "\n",
    "![5_32](./img/5_32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `5. 인공신경망 학습의 과제 ` 마무리\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### references\n",
    "\n",
    "+ Deep Learning - Ian Goodfellow [deeplearningbook.org/](https://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../../src/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[부록 컨텐츠\\]\n",
    "\n",
    "---\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 넘파이(numpy)의 `np` 별칭\n",
    "  + [numpy Stylistic Guidelines](https://docs.scipy.org/doc/numpy/dev/#stylistic-guidelines)\n",
    "  \n",
    " \n",
    "+ 블로그 글 : [medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d](https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델이 학습되면서 변화를 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화시 한글 폰트 설정을 위한 패키지\n",
    "import matplotlib.font_manager as fm\n",
    "# 시각화시 한글 폰트 설정을 위한 패키지\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "tag = HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.cell.code_cell.rendered.selected div.input').hide();\n",
    "    } else {\n",
    "        $('div.cell.code_cell.rendered.selected div.input').show();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">폰트설정 코드</a>''')\n",
    "display(tag)\n",
    "\n",
    "\n",
    "# plt 폰트 설정\n",
    "\n",
    "fm._rebuild() # 폰트 관련 캐시 삭제\n",
    "font_fname = '../../src/d2coding.ttf'\n",
    "font_family = fm.FontProperties(fname=font_fname).get_name()\n",
    "\n",
    "plt.rcParams[\"font.family\"] = font_family\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "X1_1 = np.random.normal(25, 8, 1000)\n",
    "X1_2 = np.random.normal(80, 10, 1000)\n",
    "X1_3 = np.random.normal(50, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_1 = np.random.normal(30, 8, 1000)\n",
    "X2_2 = np.random.normal(40, 10, 1000)\n",
    "X2_3 = np.random.normal(70, 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_1 = np.where(X1_1 > 100, 100, X1_1)\n",
    "X1_2 = np.where(X1_2 > 100, 100, X1_2)\n",
    "X1_3 = np.where(X1_3 > 100, 100, X1_3)\n",
    "\n",
    "X2_1 = np.where(X2_1 > 100, 100, X2_1)\n",
    "X2_2 = np.where(X2_2 > 100, 100, X2_2)\n",
    "X2_3 = np.where(X2_3 > 100, 100, X2_3)\n",
    "\n",
    "X1_1 = np.where(X1_1 <= 0, 0, X1_1)\n",
    "X1_2 = np.where(X1_2 <= 0, 0, X1_2)\n",
    "X1_3 = np.where(X1_3 <= 0, 0, X1_3)\n",
    "\n",
    "X2_1 = np.where(X2_1 <= 0, 0, X2_1)\n",
    "X2_2 = np.where(X2_2 <= 0, 0, X2_2)\n",
    "X2_3 = np.where(X2_3 <= 0, 0, X2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = np.full_like(X1_1, 0)\n",
    "Y_2 = np.full_like(X1_2, 1)\n",
    "Y_3 = np.full_like(X1_3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.concatenate([X1_1, X1_2, X1_3])\n",
    "X2 = np.concatenate([X2_1, X2_2, X2_3])\n",
    "Y = np.concatenate([Y_1, Y_2, Y_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"분류할 데이터\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_max = X1.max()\n",
    "X1_min = X1.min()\n",
    "X2_max = X2.max()\n",
    "X2_min = X2.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_p = (X1 - X1_min) / (X1_max - X1_min)\n",
    "X2_p = (X2 - X2_min) / (X2_max - X2_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([X1_p, X2_p], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ohe = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(2)\n",
    "dense_1 = Dense(40,\"relu\")(inputs)\n",
    "\n",
    "dense_2 = Dense(40,\"relu\")(dense_1)\n",
    "\n",
    "outputs = Dense(3, \"softmax\")(dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CategoricalCrossentropy()\n",
    "optim = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optim, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_range = np.arange(0, 100)\n",
    "X1_range_p = (X1_range - X1_min)/(X1_max - X1_min)\n",
    "\n",
    "X2_range = np.arange(0, 100)\n",
    "X2_range_p = (X2_range - X2_min)/(X2_max - X2_min)\n",
    "X1_mesh, X2_mesh = np.meshgrid(X1_range_p, X2_range_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mesh = np.stack([X1_mesh, X2_mesh], axis=-1).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 진행되지 않은 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n 회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_learning=20\n",
    "\n",
    "for n in range(n_learning):\n",
    "    n = n + 1\n",
    "    model.fit(X,Y_ohe,\n",
    "             epochs=1,\n",
    "             validation_split=0.1)\n",
    "    Y_pred = model.predict(X_mesh)\n",
    "    Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "    Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "    plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "    plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "    plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "    plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "    plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "    plt.title(f\"학습이 {n}회 진행된 인공신경망 모델의 분류 예측\")\n",
    "    plt.xlim([0, 100])\n",
    "    plt.ylim([0, 100])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./img/6_img/{n}.png\",\n",
    "                       bbox_inces='tight',\n",
    "                       pad_inches=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y_ohe,\n",
    "         epochs=1,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 1회 진행된 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y_ohe,\n",
    "         epochs=1,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 2회 진행된 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y_ohe,\n",
    "         epochs=3,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 5회 진행된 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y_ohe,\n",
    "         epochs=5,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 10회 진행된 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20회 학습시 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y_ohe,\n",
    "         epochs=10,\n",
    "         validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_mesh)\n",
    "Y_pred = np.argmax(Y_pred, axis=-1)\n",
    "Y_pred = Y_pred.reshape(X1_range.size,X2_range.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X1_1,X2_1,c = \"C0\",s=3, alpha=0.5, label=\"a\")\n",
    "plt.scatter(X1_2,X2_2,c = \"C1\",s=3, alpha=0.5, label=\"b\")\n",
    "plt.scatter(X1_3,X2_3,c = \"C2\",s=3, alpha=0.5, label=\"c\")\n",
    "\n",
    "plt.contourf(X1_range, X2_range, Y_pred, alpha= 0.2, cmap =\"Set3\")\n",
    "\n",
    "plt.xticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=12)\n",
    "plt.title(\"학습이 20회 진행된 인공신경망 모델의 분류 예측\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 10, 30)\n",
    "y_lr = 0.5*x + 2\n",
    "y = y_lr + np.random.normal(0,0.5,size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(이때, 각 유닛에서의 선형결합은 $a_1^{[l]}$에 대해서 역함수에 해당한다.)<br>\n",
    "\n",
    "역함수정리 : $\\frac{\\partial y}{\\partial x} = \\frac{1}{\\frac{\\partial x}{\\partial y}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(x,y, c=\"C0\", label=\"data\")\n",
    "plt.plot(x,y_lr, c=\"C1\", label=r\"$\\hat{y} = β_1x + β_0$\")\n",
    "\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_lr = np.arange(8000, 18000) # 추세선을 그릴 x의 범위\n",
    "\n",
    "y_red = 0.05 * x_lr + 100\n",
    "y_green = 0.08 * x_lr - 240\n",
    "y_blue = 0.12 * x_lr - 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"영화 '보고싶어요 수'에 따른 '총 관객수'\")\n",
    "plt.xlabel(r\"피쳐($x$): 보고싶어요 수(명)\")\n",
    "plt.ylabel(r\"라벨($y$): 총 관객 수(만명)\"); \n",
    "\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.plot(x_lr, y_red,\"r--\", label=r\"$\\hat y_{red} = 0.05x+100$\")\n",
    "plt.plot(x_lr, y_green,\"g--\", label=r\"$\\hat y_{green} = 0.08x-240$\")\n",
    "plt.plot(x_lr, y_blue,\"b--\", label=r\"$\\hat y_{blue} = 0.12x-660$\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 선형방정식 예시\n",
    "model_red = lambda x: 0.05*x + 100\n",
    "model_green = lambda x: 0.08*x - 240\n",
    "model_blue = lambda x: 0.12*x - 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"영화 '보고싶어요 수'에 따른 '총 관객수'\")\n",
    "plt.xlabel(r\"피쳐($x$): 보고싶어요 수(명)\")\n",
    "plt.ylabel(r\"라벨($y$): 총 관객 수(만명)\"); \n",
    "\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.plot(x_lr, y_red,\"r--\", label=r\"$\\hat y_{red} = 0.05x+100$\")\n",
    "plt.plot(x_lr, y_green,\"g--\", label=r\"$\\hat y_{green} = 0.08x-240$\")\n",
    "plt.plot(x_lr, y_blue,\"b--\", label=r\"$\\hat y_{blue} = 0.12x-660$\")\n",
    "\n",
    "plt.axvline(input_x, lw=1, ls=\"--\", c=\"C1\", label=\"예측 입력값\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# 각 선형방정식을 통한 입력과 출력\n",
    "x_lr = np.array([8000, 18000])\n",
    "y_red = model_red(x_lr)\n",
    "y_green = model_green(x_lr)\n",
    "y_blue = model_blue(x_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# 시각화로 확인하기\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.plot(x_lr, y_red,\"r--\")\n",
    "plt.plot(x_lr, y_green,\"g--\")\n",
    "plt.plot(x_lr, y_blue,\"b--\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.965px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
